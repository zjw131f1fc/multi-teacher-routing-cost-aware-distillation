# ===== BasicTianshouTrainer示例配置 - DQN算法 =====

# ==================== 全局设置 ====================
global_settings:
  device: "cuda"  # "cuda" 或 "cpu"
  seed: 42

# ==================== Trainer设置 ====================
trainer_settings:
  name: "basic-tianshou"

  rl_settings:
    # ===== 训练类型 =====
    trainer_type: "offpolicy"  # "onpolicy" 或 "offpolicy"

    # ===== 训练参数 =====
    max_epoch: 10
    step_per_epoch: 10000
    batch_size: 64

    # ===== Offpolicy专用参数 =====
    step_per_collect: 10       # 每次collect多少步
    update_per_step: 0.1       # 每步更新多少次（可以<1）

    # ===== Buffer设置 =====
    buffer_size: 20000
    buffer_type: "replay"  # "replay" 或 "prioritized"

    # ===== 评估设置 =====
    episode_per_test: 10
    test_in_train: true  # 训练中是否定期评估

# ==================== 环境设置 ====================
env_settings:
  # 环境名称（标准gym环境，或自定义环境）
  name: "CartPole-v1"

  # 环境数量
  num_train_envs: 10
  num_test_envs: 1

  # 是否使用多进程环境
  use_subproc: false

# ==================== Policy设置 ====================
policy_settings:
  # ===== 算法选择 =====
  algorithm: "dqn"  # "dqn", "ppo", "sac", "custom"

  # ===== DQN算法参数 =====
  dqn:
    lr: 0.001
    discount_factor: 0.99
    estimation_step: 3
    target_update_freq: 320

  # ===== 网络结构（通用） =====
  network:
    hidden_sizes: [128, 128, 64]
    activation: "relu"

# ==================== Manager设置 ====================
manager_settings:
  mode: "basic"  # "basic" 或 "optuna"

# ==================== 评估设置 ====================
evaluation_settings:
  # 自定义评估（可选，在代码中注册eval_fn）
  custom_eval: false
